import json

from google.cloud import bigquery as bq


class Config:
    def __init__(self, project_id=None, dataset_id=None):
        self.config_dict = json.load(open("config.json", "rb"))
        self.project_id = (
            project_id if project_id else self.config_dict["project_id"]
        )
        self.dataset_id = (
            dataset_id if dataset_id else self.config_dict["dataset_id"]
        )

    def client(self):
        """
        :return: bq.Client
        """
        return bq.Client(project=self.project_id)

    def table_ref(self, table_id, client=None):
        """
        :param client: bq.Client or None, if None, populated with config.json attr
        :param table_id: str
        :return: table_ref
        """
        if not client:
            client = self.client()
        return client.dataset(dataset_id=self.dataset_id).table(
            table_id=table_id
        )

    @staticmethod
    def load_job_config():
        """
        Return a load job config with 'write_disposition="WRITE_TRUNCATE"'
        :return: bq.LoadJobConfig
        """
        return bq.LoadJobConfig(write_disposition="WRITE_TRUNCATE")

    def query_job_config(self, table_id, client=None):
        """
        Return a query job config with 'write_disposition="WRITE_APPEND"' and
        'destination=table_ref' where <table_ref> is generated by self.table_ref(table_id, client)
        :param table_ref: bq.Client.Dataset.Table
        :return:
        """

        table_ref = self.table_ref(table_id, client)
        return bq.QueryJobConfig(
            write_disposition="WRITE_APPEND", destination=table_ref
        )
