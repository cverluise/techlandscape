vars:
  - bq:
      project: patentcity
      dataset: techdiffusion
      staging_dataset: stage
      robustness_dataset: robustness
      credentials: credentials_bq.json
  - gs:
      tmp: gs://tmp
  - expansion:
      niter: 10

stages:
  candidates:
    cmd: |
      ls configs/candidates_*.yaml | cut -d_ -f2 | parallel -j 8 --eta 'python techlandscape/candidates.py get-candidates configs/candidates_{} ${bq.project}.${bq.dataset}.candidates_{.} ${bq.credentials}'
      ls configs/candidates_*.yaml | cut -d_ -f2 | parallel -j 8 --eta 'python techlandscape/candidates.py get-candidates-sample ${bq.project}.${bq.dataset}.candidates_{.} ${bq.credentials} --destination-table ${bq.project}.${bq.dataset}.candidates_{.}_sample'
      ls configs/candidates_*.yaml | cut -d_ -f2 | parallel -j 8 --eta 'bq extract --destination_format NEWLINE_DELIMITED_JSON ${bq.project}:${bq.dataset}.candidates_{.}_sample ${gs.tmp}/candidates_{.}_sample.jsonl'
      gsutil cp "${gs.tmp}/candidates_*_sample.jsonl" data/
      ls configs/candidates_*.yaml | cut -d/ -f2 | parallel -j 8 --eta 'mv data/{.}_sample.jsonl data/{.}_sample.tmp.jsonl && python techlandscape/candidates.py prep-prodigy-annotation data/{.}_sample.tmp.jsonl configs/{} >> data/{.}_sample.jsonl' && rm data/*.tmp.*
    deps:
      - configs/candidates_additivemanufacturing.yaml
      - configs/candidates_computervision.yaml
      - configs/candidates_genomeediting.yaml
      - configs/candidates_naturallanguageprocessing.yaml
      - configs/candidates_blockchain.yaml
      - configs/candidates_culturedmeat.yaml
      - configs/candidates_hydrogenstorage.yaml
      - configs/candidates_selfdrivingvehicle.yaml

  load-annotated-seed:
    cmd: |
      # prep seed file
      ls data/seed_*.jsonl | parallel 'mv {} {}.tmp && techlandscape utils add-practical-fields {}.tmp >> {}'
      rm data/seed_*.jsonl.tmp
      # load to bq
      cd data && ls seed_*.jsonl | parallel 'bq load --source_format NEWLINE_DELIMITED_JSON --replace --ignore_unknown_values --max_bad_records 1000 --autodetect ${bq.project}:${bq.dataset}.{.} {} ../schemas/seed.json' && cd ../
    deps:
      - schemas/seed.json
      - data/seed_additivemanufacturing.jsonl
      - data/seed_computervision.jsonl
      - data/seed_hydrogenstorage.jsonl
      - data/seed_selfdrivingvehicle.jsonl
      - data/seed_blockchain.jsonl
      - data/seed_genomeediting.jsonl
      - data/seed_naturallanguageprocessing.jsonl

  expansion-robustness:
    foreach:
      - .5
      - .7
      - .9
    do:
      cmd: |
        # clean expansion datasets
        bq ls --max_results 9999 "${bq.project}:${bq.staging_dataset}" | grep expansion | awk '{print $1}' | parallel 'bq rm -f ${bq.project}:${bq.staging_dataset}.{}'
        bq ls --max_results 9999 "${bq.project}:${bq.robustness_dataset}" | grep expansion | awk '{print $1}' | parallel 'bq rm -f ${bq.project}:${bq.robustness_dataset}.{}'
        # generate expansions and analyses
        parallel --eta 'techlandscape expansion get-expansion family_id cpc ${bq.project}.${bq.dataset}.seed_{2} patentcity.${bq.robustness_dataset}.{1}_expansion_{2} patentcity.stage ${bq.credentials} --random-share ${item}' ::: $(pwgen 5 ${expansion.niter}) ::: $(cat lib/technology.txt)
        parallel --eta 'techlandscape robustness get-overlap-analysis {} batch ${bq.credentials} --summary --destination outs/expansion_{}_batchrobustness${item}.csv' ::: $(cat lib/technology.txt)
        parallel --eta 'techlandscape robustness get-overlap-analysis {} pairwise ${bq.credentials} --summary --destination outs/expansion_{}_pairwiserobustness${item}.csv'  ::: $(cat lib/technology.txt)
